{% set version = "23.0.0" %}
{% set cuda_enabled = cuda_compiler_version != "None" %}
{% set build_ext_version = "5.0.0" %}
{% set build_ext = "cuda" if cuda_enabled else "cpu" %}
{% set proc_build_number = "0" %}
{% set llvm_version = "21" %}

# see https://github.com/apache/arrow/blob/apache-arrow-10.0.1/cpp/CMakeLists.txt#L88-L90
{% set so_version = (version.split(".")[0] | int * 100 + version.split(".")[1] | int) ~ "." ~ version.split(".")[2] ~ ".0" %}

package:
  name: apache-arrow
  version: {{ version }}

source:
  - url: https://www.apache.org/dyn/closer.lua/arrow/arrow-{{ version }}/apache-arrow-{{ version }}.tar.gz?action=download
    fn: apache-arrow-{{ version }}.tar.gz
    sha256: 12f6844a0ba3b99645cd2bc6cc4f44f6a174ab90da37e474f08b7d073433cb60
    patches:
      # skip gcsfs tests due to missing `storage-testbench`
      - patches/0001-disable-gcsfs_test.patch
      # upstream problems on with s3 tests on osx, see
      # https://github.com/apache/arrow/issues/35587
      - patches/0002-skip-NonExistentBucket-test-on-osx.patch
      # backport https://github.com/apache/arrow/pull/48895
      - patches/0003-GH-48894-Python-C-Use-base-Azure-Core-RequestFailedE.patch
      # backport https://github.com/apache/arrow/pull/48601
      - patches/0004-GH-48593-C-C-20-use-standard-calendar-timezone-APIs.patch      # [win]
      # disable gandiva tests that are "unmaintained" and failing on windows
      - patches/0005-disable-some-gandiva-tests-related-to-tzdb-handling.patch      # [win]

  # testing-submodules not part of release tarball
  - git_url: https://github.com/apache/arrow-testing.git
    git_rev: 19dda67f485ffb3ffa92f4c6fa083576ef052d58
    folder: testing
  - git_url: https://github.com/apache/parquet-testing.git
    git_rev: a3d96a65e11e2bbca7d22a894e8313ede90a33a3
    folder: cpp/submodules/parquet-testing

build:
  number: 0
  # for cuda support, building with one version is enough to be compatible with
  # all later versions, since arrow is only using libcuda, and not libcudart.
  skip: true  # [cuda_compiler_version not in ("None", cuda_compiler_version_min)]

requirements:
  build:
    - {{ compiler("c") }}
    - {{ stdlib("c") }}
    - {{ compiler("cxx") }}
    - {{ compiler("cuda") }}                 # [cuda_compiler_version != "None"]
    # needs to run protoc & grpc_cpp_plugin
    - libgrpc                                # [build_platform != target_platform]
    - libprotobuf                            # [build_platform != target_platform]
    # needed for gandiva
    - clangdev {{ llvm_version }}            # [build_platform != target_platform]
    - llvmdev {{ llvm_version }}             # [build_platform != target_platform]
    - gnuconfig                              # [build_platform != target_platform]
    - cmake
    - ninja
    # necessary for vendored jemalloc
    - autoconf     # [unix]
    - make         # [unix]
    # where orc ends up looking (because during build, CONDA_PREFIX==BUILD_PREFIX)
    - tzdata
  host:
    # for required dependencies, see
    # https://github.com/apache/arrow/blob/apache-arrow-11.0.0/cpp/cmake_modules/ThirdpartyToolchain.cmake#L46-L75
    - clangdev {{ llvm_version }}
    - llvmdev {{ llvm_version }}
    - aws-crt-cpp
    - aws-sdk-cpp
    # azure filesystem dependencies, currently broken on windows, see
    # https://github.com/apache/arrow/issues/41990
    - azure-core-cpp                    # [unix]
    - azure-identity-cpp                # [unix]
    - azure-storage-blobs-cpp           # [unix]
    - azure-storage-files-datalake-cpp  # [unix]
    - brotli
    - bzip2
    - gflags
    - glog
    # arrow uses a customized jemalloc, see #944
    # - jemalloc
    - libabseil
    - libboost-devel
    - libgoogle-cloud-devel
    - libgoogle-cloud-storage-devel
    - libgrpc
    # see https://github.com/apache/arrow/issues/45033
    - libopentelemetry-cpp          # [unix]
    - libprotobuf
    - libutf8proc
    - lz4-c
    - nlohmann_json
    - orc
    - rapidjson
    - re2
    - snappy
    - thrift-cpp
    - xsimd
    - zlib
    - zstd
    # test requirements, c.f.
    # https://github.com/apache/arrow/blob/apache-arrow-22.0.0/cpp/CMakeLists.txt#L689
    - gtest         # [build_platform == target_platform]
    # https://github.com/apache/arrow/blob/apache-arrow-22.0.0/cpp/src/arrow/flight/sql/CMakeLists.txt#L112-L113
    - sqlite *      # [build_platform == target_platform]
    # required by s3fs tests
    - minio-server  # [build_platform == target_platform]
    # for npm, to install azurite
    - nodejs >=22   # [build_platform == target_platform]

outputs:
  - name: apache-arrow-proc
    version: {{ build_ext_version }}
    build:
      number: {{ proc_build_number }}
      string: {{ build_ext }}
    requirements:
      run_constrained:
        # avoid installation with old naming of proc package
        - arrow-cpp-proc <0.0a0
    test:
      commands:
        - exit 0
    about:
      home: http://github.com/apache/arrow
      license: Apache-2.0
      license_file:
        - LICENSE.txt
      summary: A meta-package to select Arrow build variant

  - name: libarrow-all
    script: install-libarrow.sh  # [unix]
    script: install-libarrow.bat  # [win]
    version: {{ version }}
    build:
      string: h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}_{{ build_ext }}
      run_exports:
        - {{ pin_subpackage("libarrow", max_pin="x.x") }}
        - {{ pin_subpackage("libarrow-acero", max_pin="x.x") }}
        - {{ pin_subpackage("libarrow-dataset", max_pin="x.x") }}
        - {{ pin_subpackage("libarrow-flight", max_pin="x.x") }}
        - {{ pin_subpackage("libarrow-flight-sql", max_pin="x.x") }}
        - {{ pin_subpackage("libarrow-gandiva", max_pin="x.x") }}
        - {{ pin_subpackage("libarrow-substrait", max_pin="x.x") }}
        - {{ pin_subpackage("libparquet", max_pin="x.x") }}
    requirements:
      build:
        - cmake
        - ninja
      host:
        - {{ pin_subpackage("libarrow", exact=True) }}
        - {{ pin_subpackage("libarrow-acero", exact=True) }}
        - {{ pin_subpackage("libarrow-compute", exact=True) }}
        - {{ pin_subpackage("libarrow-dataset", exact=True) }}
        - {{ pin_subpackage("libarrow-flight", exact=True) }}
        - {{ pin_subpackage("libarrow-flight-sql", exact=True) }}
        - {{ pin_subpackage("libarrow-gandiva", exact=True) }}
        - {{ pin_subpackage("libarrow-substrait", exact=True) }}
        - {{ pin_subpackage("libparquet", exact=True) }}
        - {{ pin_subpackage("arrow-utils", exact=True) }}
        - {{ pin_subpackage("parquet-utils", exact=True) }}
      run:
        - {{ pin_subpackage("libarrow", exact=True) }}
        - {{ pin_subpackage("libarrow-acero", exact=True) }}
        - {{ pin_subpackage("libarrow-compute", exact=True) }}
        - {{ pin_subpackage("libarrow-dataset", exact=True) }}
        - {{ pin_subpackage("libarrow-flight", exact=True) }}
        - {{ pin_subpackage("libarrow-flight-sql", exact=True) }}
        - {{ pin_subpackage("libarrow-gandiva", exact=True) }}
        - {{ pin_subpackage("libarrow-substrait", exact=True) }}
        - {{ pin_subpackage("libparquet", exact=True) }}
        - {{ pin_subpackage("arrow-utils", exact=True) }}
        - {{ pin_subpackage("parquet-utils", exact=True) }}
    test:
      commands:
        # absence of test bits
        - test ! -f $PREFIX/lib/libarrow_testing.so                 # [unix]
        - test ! -d $PREFIX/lib/cmake/ArrowTesting                  # [unix]
        - test ! -f $PREFIX/lib/pkgconfig/arrow-testing.pc          # [unix]
        - if exist %LIBRARY_BIN%\arrow_testing.dll exit 1           # [win]
        - if exist %LIBRARY_LIB%\arrow_testing.lib exit 1           # [win]
        - if exist %LIBRARY_LIB%\cmake\ArrowTesting exit 1          # [win]
        - if exist %LIBRARY_LIB%\pkgconfig\arrow-testing.pc exit 1  # [win]

    about:
      home: http://github.com/apache/arrow
      license: Apache-2.0
      license_file:
        - LICENSE.txt
      summary: C++ libraries for Apache Arrow

  - name: libarrow
    script: install-libarrow.sh  # [unix]
    script: install-libarrow.bat  # [win]
    version: {{ version }}
    build:
      string: h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}_{{ build_ext }}
      run_exports:
        - {{ pin_subpackage("libarrow", max_pin="x.x") }}
      ignore_run_exports_from:
        - {{ compiler("cuda") }}                 # [cuda_compiler_version != "None"]
        - gflags
        # shared lib linked on unix, not on win
        - glog                                   # [win]
      ignore_run_exports:
        # we don't need all of brotli's run-exports
        - libbrotlicommon
      missing_dso_whitelist:
        - '*/libcuda.so.*'    # [linux]
        - '*/nvcuda.dll'      # [win]
    requirements:
      build:
        - cmake
        - ninja
        # for strong run-exports
        - {{ stdlib("c") }}
        - {{ compiler("c") }}
        - {{ compiler("cxx") }}
        - {{ compiler("cuda") }}                 # [cuda_compiler_version != "None"]
      host:
        - aws-crt-cpp
        - aws-sdk-cpp
        - azure-core-cpp                    # [unix]
        - azure-identity-cpp                # [unix]
        - azure-storage-blobs-cpp           # [unix]
        - azure-storage-files-datalake-cpp  # [unix]
        - brotli
        - bzip2
        - gflags
        - glog
        # arrow uses a customized jemalloc, see #944
        # - jemalloc
        - libabseil
        - libgoogle-cloud-devel
        - libgoogle-cloud-storage-devel
        - libopentelemetry-cpp              # [unix]
        - libprotobuf
        - lz4-c
        - orc
        - snappy
        - zlib
        - zstd
        - __cuda >={{ cuda_compiler_version_min }}  # [cuda_compiler_version != "None"]
        # since libgoogle-cloud{,-storage} is static on windows, see
        # https://github.com/conda-forge/google-cloud-cpp-feedstock/pull/108,
        # its host deps (which aren't yet covered above) leak into the build here
        - libcrc32c  # [win]
        - libcurl    # [win]
      run_constrained:
        - apache-arrow-proc =*={{ build_ext }}
        # avoid installation with old naming of lib package
        - arrow-cpp <0.0a0
        # old parquet lib output, now part of this feedstock
        - parquet-cpp <0.0a0
        # since all the other libarrow-* variants in this recipe depend exactly on libarrow,
        # this avoids that libarrow-X & -Y get installed with different builds or versions.

    test:
      commands:
        # headers
        - test -f $PREFIX/include/arrow/api.h               # [unix]
        - if not exist %LIBRARY_INC%\arrow\api.h exit 1     # [win]

        {% set libs = ["arrow"] + (cuda_compiler_version != "None") * ["arrow_cuda"] %}
        {% for each_lib in libs %}
        # shared
        - test -f $PREFIX/lib/lib{{ each_lib }}.so                 # [linux]
        - test -f $PREFIX/lib/lib{{ each_lib }}.dylib              # [osx]
        # Ensure symlinks are preserved
        - test -L $PREFIX/lib/lib{{ each_lib }}.so                 # [linux]
        - test -L $PREFIX/lib/lib{{ each_lib }}.dylib              # [osx]
        - if not exist %LIBRARY_BIN%\{{ each_lib }}.dll exit 1     # [win]
        - if not exist %LIBRARY_LIB%\{{ each_lib }}.lib exit 1     # [win]

        # absence of static libraries
        - test ! -f $PREFIX/lib/lib{{ each_lib }}.a                # [unix]
        - if exist %LIBRARY_LIB%\{{ each_lib }}_static.lib exit 1  # [win]
        {% endfor %}

        # absence of arrow_cuda for CPU builds
        - test ! -f $PREFIX/lib/libarrow_cuda.so                   # [(cuda_compiler_version == "None") and linux]
        - test ! -f $PREFIX/lib/libarrow_cuda.a                    # [(cuda_compiler_version == "None") and linux]
        - if exist %LIBRARY_BIN%\arrow_cuda.dll exit 1             # [(cuda_compiler_version == "None") and win]
        - if exist %LIBRARY_LIB%\arrow_cuda.lib exit 1             # [(cuda_compiler_version == "None") and win]
        - if exist %LIBRARY_LIB%\arrow_cuda_static.lib exit 1      # [(cuda_compiler_version == "None") and win]

        # gdb-wrapper (paths are stacked intentionally)
        - test -f $PREFIX/share/gdb/auto-load/$PREFIX/lib/libarrow.so.{{ so_version }}-gdb.py     # [linux]
        - test -f $PREFIX/share/gdb/auto-load/$PREFIX/lib/libarrow.{{ so_version }}.dylib-gdb.py  # [osx]

        {% set libs = [
            "arrow_acero", "arrow_dataset", "arrow_flight",
            "arrow_flight_sql", "arrow_substrait", "gandiva", "parquet"
        ] %}
        {% for each_lib in libs %}
        # absence of libraries that belong in other outputs
        - test ! -f $PREFIX/lib/lib{{ each_lib }}.so                # [linux]
        - test ! -f $PREFIX/lib/lib{{ each_lib }}.dylib             # [osx]
        - if exist %LIBRARY_BIN%\{{ each_lib }}.dll exit 1          # [win]
        - if exist %LIBRARY_LIB%\{{ each_lib }}.lib exit 1          # [win]
        {% endfor %}

    about:
      home: http://github.com/apache/arrow
      license: Apache-2.0
      license_file:
        - LICENSE.txt
      summary: C++ libraries for Apache Arrow core

  - name: libarrow-acero
    script: install-libarrow.sh  # [unix]
    script: install-libarrow.bat  # [win]
    version: {{ version }}
    build:
      string: h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}_{{ build_ext }}
      run_exports:
        - {{ pin_subpackage("libarrow-acero", max_pin="x.x") }}
    requirements:
      build:
        - cmake
        - ninja
        # for strong run-exports
        - {{ stdlib("c") }}
        - {{ compiler("c") }}
        - {{ compiler("cxx") }}
      host:
        - {{ pin_subpackage("libarrow", exact=True) }}
        - {{ pin_subpackage("libarrow-compute", exact=True) }}
        - libabseil             # [osx]
        - libprotobuf           # [osx]
        - libopentelemetry-cpp  # [osx]
      run:
        - {{ pin_subpackage("libarrow", exact=True) }}
        - {{ pin_subpackage("libarrow-compute", exact=True) }}
      # run-constraints handled by libarrow, since we depend on it with exact=True

    test:
      commands:
        # headers
        - test -f $PREFIX/include/arrow/acero/api.h             # [unix]
        - if not exist %LIBRARY_INC%\arrow\acero\api.h exit 1   # [win]

        # shared libraries
        - test -f $PREFIX/lib/libarrow_acero.so                 # [linux]
        - test -f $PREFIX/lib/libarrow_acero.dylib              # [osx]
        - if not exist %LIBRARY_BIN%\arrow_acero.dll exit 1     # [win]
        - if not exist %LIBRARY_LIB%\arrow_acero.lib exit 1     # [win]

        # absence of static libraries
        - test ! -f $PREFIX/lib/libarrow_acero.a                # [unix]
        - if exist %LIBRARY_LIB%\arrow_acero_static.lib exit 1  # [win]

    about:
      home: http://github.com/apache/arrow
      license: Apache-2.0
      license_file:
        - LICENSE.txt
      summary: C++ libraries for Apache Arrow Acero

  - name: libarrow-compute
    script: install-libarrow.sh  # [unix]
    script: install-libarrow.bat  # [win]
    version: {{ version }}
    build:
      string: h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}_{{ build_ext }}
      run_exports:
        - {{ pin_subpackage("libarrow-compute", max_pin="x.x") }}
    requirements:
      build:
        - cmake <4
        - ninja
        # for strong run-exports
        - {{ stdlib("c") }}
        - {{ compiler("c") }}
        - {{ compiler("cxx") }}
      host:
        - {{ pin_subpackage("libarrow", exact=True) }}
        - libabseil             # [osx]
        - libopentelemetry-cpp  # [osx]
        - libprotobuf           # [osx]
        - libutf8proc
        - re2
      run:
        - {{ pin_subpackage("libarrow", exact=True) }}
      # run-constraints handled by libarrow, since we depend on it with exact=True

    test:
      commands:
        # headers
        - test -f $PREFIX/include/arrow/compute/api.h               # [unix]
        - if not exist %LIBRARY_INC%\arrow\compute\api.h exit 1     # [win]

        # shared libraries
        - test -f $PREFIX/lib/libarrow_compute.so                   # [linux]
        - test -f $PREFIX/lib/libarrow_compute.dylib                # [osx]
        - if not exist %LIBRARY_BIN%\arrow_compute.dll exit 1       # [win]
        - if not exist %LIBRARY_LIB%\arrow_compute.lib exit 1       # [win]

        # absence of static libraries
        - test ! -f $PREFIX/lib/libarrow_compute.a                  # [unix]
        - if exist %LIBRARY_LIB%\arrow_compute_static.lib exit 1    # [win]

    about:
      home: http://github.com/apache/arrow
      license: Apache-2.0
      license_file:
        - LICENSE.txt
      summary: C++ libraries for Apache Arrow Compute

  - name: libarrow-dataset
    script: install-libarrow.sh  # [unix]
    script: install-libarrow.bat  # [win]
    version: {{ version }}
    build:
      string: h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}_{{ build_ext }}
      run_exports:
        - {{ pin_subpackage("libarrow-dataset", max_pin="x.x") }}
    requirements:
      build:
        - cmake
        - ninja
        # for strong run-exports
        - {{ stdlib("c") }}
        - {{ compiler("c") }}
        - {{ compiler("cxx") }}
      host:
        - {{ pin_subpackage("libarrow", exact=True) }}
        - {{ pin_subpackage("libarrow-acero", exact=True) }}
        - {{ pin_subpackage("libarrow-compute", exact=True) }}
        - {{ pin_subpackage("libparquet", exact=True) }}
        - libabseil             # [osx]
        - libprotobuf           # [osx]
        - libopentelemetry-cpp  # [osx]
      run:
        - {{ pin_subpackage("libarrow", exact=True) }}
        - {{ pin_subpackage("libarrow-acero", exact=True) }}
        - {{ pin_subpackage("libarrow-compute", exact=True) }}
        - {{ pin_subpackage("libparquet", exact=True) }}
      # run-constraints handled by libarrow, since we depend on it with exact=True

    test:
      commands:
        # headers
        - test -f $PREFIX/include/arrow/dataset/api.h               # [unix]
        - if not exist %LIBRARY_INC%\arrow\dataset\api.h exit 1     # [win]

        # shared libraries
        - test -f $PREFIX/lib/libarrow_dataset.so                   # [linux]
        - test -f $PREFIX/lib/libarrow_dataset.dylib                # [osx]
        - if not exist %LIBRARY_BIN%\arrow_dataset.dll exit 1       # [win]
        - if not exist %LIBRARY_LIB%\arrow_dataset.lib exit 1       # [win]

        # absence of static libraries
        - test ! -f $PREFIX/lib/libarrow_dataset.a                  # [unix]
        - if exist %LIBRARY_LIB%\arrow_dataset_static.lib exit 1    # [win]

    about:
      home: http://github.com/apache/arrow
      license: Apache-2.0
      license_file:
        - LICENSE.txt
      summary: C++ libraries for Apache Arrow Dataset

  - name: libarrow-flight
    script: install-libarrow.sh  # [unix]
    script: install-libarrow.bat  # [win]
    version: {{ version }}
    build:
      string: h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}_{{ build_ext }}
      run_exports:
        - {{ pin_subpackage("libarrow-flight", max_pin="x.x") }}
    requirements:
      build:
        - cmake
        - ninja
        # for strong run-exports
        - {{ stdlib("c") }}
        - {{ compiler("c") }}
        - {{ compiler("cxx") }}
        # needs to run protoc & grpc_cpp_plugin
        - libgrpc                                # [build_platform != target_platform]
        - libprotobuf                            # [build_platform != target_platform]
      host:
        - {{ pin_subpackage("libarrow", exact=True) }}
        - libabseil
        - libgrpc
        - libprotobuf
        - libopentelemetry-cpp  # [osx]
      run:
        - {{ pin_subpackage("libarrow", exact=True) }}
      # run-constraints handled by libarrow, since we depend on it with exact=True

    test:
      commands:
        # headers
        - test -f $PREFIX/include/arrow/flight/types.h              # [unix]
        - if not exist %LIBRARY_INC%\arrow\flight\types.h exit 1    # [win]

        # shared libraries
        - test -f $PREFIX/lib/libarrow_flight.so                    # [linux]
        - test -f $PREFIX/lib/libarrow_flight.dylib                 # [osx]
        - if not exist %LIBRARY_BIN%\arrow_flight.dll exit 1        # [win]
        - if not exist %LIBRARY_LIB%\arrow_flight.lib exit 1        # [win]

        # absence of static libraries
        - test ! -f $PREFIX/lib/libarrow_flight.a                   # [unix]
        - if exist %LIBRARY_LIB%\arrow_flight_static.lib exit 1     # [win]

    about:
      home: http://github.com/apache/arrow
      license: Apache-2.0
      license_file:
        - LICENSE.txt
      summary: C++ libraries for Apache Arrow Flight

  - name: libarrow-flight-sql
    script: install-libarrow.sh  # [unix]
    script: install-libarrow.bat  # [win]
    version: {{ version }}
    build:
      string: h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}_{{ build_ext }}
      run_exports:
        - {{ pin_subpackage("libarrow-flight-sql", max_pin="x.x") }}
    requirements:
      build:
        - cmake
        - ninja
        # for strong run-exports
        - {{ stdlib("c") }}
        - {{ compiler("c") }}
        - {{ compiler("cxx") }}
        # needs to run protoc & grpc_cpp_plugin
        - libgrpc                                # [build_platform != target_platform]
        - libprotobuf                            # [build_platform != target_platform]
      host:
        - {{ pin_subpackage("libarrow", exact=True) }}
        - {{ pin_subpackage("libarrow-flight", exact=True) }}
        - libabseil
        - libprotobuf
        - libgrpc               # [osx]
        - libopentelemetry-cpp  # [osx]
      run:
        - {{ pin_subpackage("libarrow", exact=True) }}
        - {{ pin_subpackage("libarrow-flight", exact=True) }}
      # run-constraints handled by libarrow, since we depend on it with exact=True

    test:
      commands:
        # headers
        - test -f $PREFIX/include/arrow/flight/sql/api.h                # [unix]
        - if not exist %LIBRARY_INC%\arrow\flight\sql\api.h exit 1      # [win]

        # shared libraries
        - test -f $PREFIX/lib/libarrow_flight_sql.so                    # [linux]
        - test -f $PREFIX/lib/libarrow_flight_sql.dylib                 # [osx]
        - if not exist %LIBRARY_BIN%\arrow_flight_sql.dll exit 1        # [win]
        - if not exist %LIBRARY_LIB%\arrow_flight_sql.lib exit 1        # [win]

        # absence of static libraries
        - test ! -f $PREFIX/lib/libarrow_flight_sql.a                   # [unix]
        - if exist %LIBRARY_LIB%\arrow_flight_sql_static.lib exit 1     # [win]

    about:
      home: http://github.com/apache/arrow
      license: Apache-2.0
      license_file:
        - LICENSE.txt
      summary: C++ libraries for Apache Arrow Flight SQL

  - name: libarrow-gandiva
    script: install-libarrow.sh  # [unix]
    script: install-libarrow.bat  # [win]
    version: {{ version }}
    build:
      string: h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}_{{ build_ext }}
      run_exports:
        - {{ pin_subpackage("libarrow-gandiva", max_pin="x.x") }}
    requirements:
      build:
        - cmake
        - ninja
        # for strong run-exports
        - {{ stdlib("c") }}
        - {{ compiler("c") }}
        - {{ compiler("cxx") }}
      host:
        - {{ pin_subpackage("libarrow", exact=True) }}
        - libabseil
        - libutf8proc
        # gandiva requires shared libllvm; needs to match version used at build time
        - llvm {{ llvm_version }}  # [unix]
        - openssl
        - re2
        - zlib  # [win]
        - zstd  # [win]
      run:
        - {{ pin_subpackage("libarrow", exact=True) }}
      # run-constraints handled by libarrow, since we depend on it with exact=True

    test:
      commands:
        # headers
        - test -f $PREFIX/include/gandiva/engine.h              # [unix]
        - if not exist %LIBRARY_INC%\gandiva\engine.h exit 1    # [win]

        # shared libraries
        - test -f $PREFIX/lib/libgandiva.so                     # [linux]
        - test -f $PREFIX/lib/libgandiva.dylib                  # [osx]
        - if not exist %LIBRARY_BIN%\gandiva.dll exit 1         # [win]
        - if not exist %LIBRARY_LIB%\gandiva.lib exit 1         # [win]

        # absence of static libraries
        - test ! -f $PREFIX/lib/libgandiva.a                    # [unix]
        - if exist %LIBRARY_LIB%\gandiva_static.lib exit 1      # [win]

    about:
      home: http://github.com/apache/arrow
      license: Apache-2.0
      license_file:
        - LICENSE.txt
      summary: C++ libraries for Apache Arrow Gandiva

  - name: libarrow-substrait
    script: install-libarrow.sh  # [unix]
    script: install-libarrow.bat  # [win]
    version: {{ version }}
    build:
      string: h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}_{{ build_ext }}
      run_exports:
        - {{ pin_subpackage("libarrow-substrait", max_pin="x.x") }}
    requirements:
      build:
        - cmake
        - ninja
        # for strong run-exports
        - {{ stdlib("c") }}
        - {{ compiler("c") }}
        - {{ compiler("cxx") }}
        - libprotobuf                            # [build_platform != target_platform]
      host:
        - {{ pin_subpackage("libarrow", exact=True) }}
        - {{ pin_subpackage("libarrow-acero", exact=True) }}
        - {{ pin_subpackage("libarrow-dataset", exact=True) }}
        - libabseil
        - libprotobuf
      run:
        - {{ pin_subpackage("libarrow", exact=True) }}
        - {{ pin_subpackage("libarrow-acero", exact=True) }}
        - {{ pin_subpackage("libarrow-dataset", exact=True) }}
      # run-constraints handled by libarrow, since we depend on it with exact=True

    test:
      commands:
        # headers
        - test -f $PREFIX/include/arrow/engine/substrait/api.h              # [unix]
        - if not exist %LIBRARY_INC%\arrow\engine\substrait\api.h exit 1    # [win]

        # shared libraries
        - test -f $PREFIX/lib/libarrow_substrait.so                         # [linux]
        - test -f $PREFIX/lib/libarrow_substrait.dylib                      # [osx]
        - if not exist %LIBRARY_BIN%\arrow_substrait.dll exit 1             # [win]
        - if not exist %LIBRARY_LIB%\arrow_substrait.lib exit 1             # [win]

        # absence of static libraries
        - test ! -f $PREFIX/lib/libarrow_substrait.a                        # [unix]
        - if exist %LIBRARY_LIB%\arrow_substrait_static.lib exit 1          # [win]

    about:
      home: http://github.com/apache/arrow
      license: Apache-2.0
      license_file:
        - LICENSE.txt
      summary: C++ libraries for Apache Arrow Substrait

  - name: libparquet
    script: install-libarrow.sh  # [unix]
    script: install-libarrow.bat  # [win]
    version: {{ version }}
    build:
      string: h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}_{{ build_ext }}
      run_exports:
        - {{ pin_subpackage("libparquet", max_pin="x.x") }}
    requirements:
      build:
        - cmake
        - ninja
        # for strong run-exports
        - {{ stdlib("c") }}
        - {{ compiler("c") }}
        - {{ compiler("cxx") }}
      host:
        - {{ pin_subpackage("libarrow", exact=True) }}
        - openssl
        - thrift-cpp
        - libabseil             # [osx]
        - libprotobuf           # [osx]
        - libopentelemetry-cpp  # [osx]
      run:
        - {{ pin_subpackage("libarrow", exact=True) }}
      # run-constraints handled by libarrow, since we depend on it with exact=True

    test:
      commands:
        # headers
        - test -f $PREFIX/include/parquet/api/reader.h              # [unix]
        - if not exist %LIBRARY_INC%\parquet\api\reader.h exit 1    # [win]

        # shared libraries
        - test -f $PREFIX/lib/libparquet.so                         # [linux]
        - test -f $PREFIX/lib/libparquet.dylib                      # [osx]
        - if not exist %LIBRARY_BIN%\parquet.dll exit 1             # [win]
        - if not exist %LIBRARY_LIB%\parquet.lib exit 1             # [win]

        # absence of static libraries
        - test ! -f $PREFIX/lib/libparquet.a                        # [unix]
        - if exist %LIBRARY_LIB%\parquet_static.lib exit 1          # [win]

    about:
      home: http://github.com/apache/arrow
      license: Apache-2.0
      license_file:
        - LICENSE.txt
      summary: C++ libraries for Apache Parquet

  - name: parquet-utils
    script: install-libarrow.sh  # [unix]
    script: install-libarrow.bat  # [win]
    version: {{ version }}
    build:
      string: h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}_{{ build_ext }}
    requirements:
      build:
        - cmake <4
        - ninja
        # for strong run-exports
        - {{ stdlib("c") }}
        - {{ compiler("c") }}
        - {{ compiler("cxx") }}
      host:
        - {{ pin_subpackage("libarrow", exact=True) }}
        - {{ pin_subpackage("libparquet", exact=True) }}
      run:
        - {{ pin_subpackage("libarrow", exact=True) }}
        - {{ pin_subpackage("libparquet", exact=True) }}

    test:
      commands:
        # bin
        - test -f $PREFIX/bin/parquet-dump-arrow-statistics                     # [unix]
        - test -f $PREFIX/bin/parquet-dump-footer                               # [unix]
        - test -f $PREFIX/bin/parquet-dump-schema                               # [unix]
        - test -f $PREFIX/bin/parquet-reader                                    # [unix]
        - test -f $PREFIX/bin/parquet-scan                                      # [unix]
        - if not exist %LIBRARY_BIN%\parquet-dump-arrow-statistics.exe exit 1   # [win]
        - if not exist %LIBRARY_BIN%\parquet-dump-footer.exe exit 1             # [win]
        - if not exist %LIBRARY_BIN%\parquet-dump-schema.exe exit 1             # [win]
        - if not exist %LIBRARY_BIN%\parquet-reader.exe exit 1                  # [win]
        - if not exist %LIBRARY_BIN%\parquet-scan.exe exit 1                    # [win]

    about:
      home: http://github.com/apache/arrow
      license: Apache-2.0
      license_file:
        - LICENSE.txt
      summary: Executables for inspecting Apache Parquet files

  - name: arrow-utils
    script: install-libarrow.sh  # [unix]
    script: install-libarrow.bat  # [win]
    version: {{ version }}
    build:
      string: h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}_{{ build_ext }}
    requirements:
      build:
        - cmake <4
        - ninja
        # for strong run-exports
        - {{ stdlib("c") }}
        - {{ compiler("c") }}
        - {{ compiler("cxx") }}
      host:
        - {{ pin_subpackage("libarrow", exact=True) }}
      run:
        - {{ pin_subpackage("libarrow", exact=True) }}

    test:
      commands:
        # bin
        - test -f $PREFIX/bin/arrow-file-to-stream                                          # [unix]
        - test -f $PREFIX/bin/arrow-stream-to-file                                          # [unix]
        - if not exist %LIBRARY_BIN%\arrow-file-to-stream.exe exit 1                        # [win]
        - if not exist %LIBRARY_BIN%\arrow-stream-to-file.exe exit 1                        # [win]

    about:
      home: http://github.com/apache/arrow
      license: Apache-2.0
      license_file:
        - LICENSE.txt
      summary: Executables for manipulating Apache arrow files

  - name: pyarrow-core
    script: build-pyarrow.sh   # [unix]
    script: build-pyarrow.bat  # [win]
    version: {{ version }}
    build:
      string: py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}_{{ build_ext }}
      ignore_run_exports_from:
        - {{ compiler("cuda") }}                 # [cuda_compiler_version != "None"]
        # we don't need numpy at runtime, just to build
        - numpy
      rpaths:
        - lib/
        - {{ SP_DIR }}/pyarrow
      missing_dso_whitelist:
        # not actually missing, but installed into SP_DIR, see tests
        - '*/arrow_python.dll'                # [win]
        - '*/arrow_python_flight.dll'         # [win]
        # pyarrow-core builds with the capabilities but we do not ship them
        # to provide the smaller core functionality.
        - 'lib/libarrow_acero.*'              # [unix]
        - 'lib/libarrow_dataset.*'            # [unix]
        - 'lib/libarrow_substrait.*'          # [unix]
        - 'lib/libarrow_flight.*'             # [unix]
        - 'lib/libparquet.*'                  # [unix]
        - 'lib/libgandiva.*'                  # [unix]
        - 'Library/lib/arrow_acero.dll'       # [win]
        - 'Library/lib/arrow_dataset.dll'     # [win]
        - 'Library/lib/arrow_substrait.dll'   # [win]
        - 'Library/lib/arrow_flight.dll'      # [win]
        - 'Library/lib/parquet.dll'           # [win]
        - 'Library/lib/gandiva.dll'           # [win]
    requirements:
      build:
        - {{ compiler("c") }}
        - {{ stdlib("c") }}
        - {{ compiler("cxx") }}
        # pyarrow does not require nvcc but it needs to link against libraries in libarrow=*=*cuda
        - {{ compiler("cuda") }}                 # [cuda_compiler_version != "None"]
        - python                                 # [build_platform != target_platform]
        - cross-python_{{ target_platform }}     # [build_platform != target_platform]
        - cython                                 # [build_platform != target_platform]
        - numpy                                  # [build_platform != target_platform]
        - cmake
        - ninja
      host:
        # We add all libarrow package dependencies on host in order
        # to build pyarrow once with all capabilities.
        - {{ pin_subpackage("libarrow-all", exact=True) }}
        - clangdev {{ llvm_version }}
        - llvmdev {{ llvm_version }}
        - zlib
        - cython
        - numpy
        - python
        - setuptools
        - setuptools-scm
      run:
        # We ignore the run-exports from libarrow-all and restrict to only
        # libarrow, as we don't want the other libraries to be installed when
        # running for pyarrow-core, where the aim is a low storage footprint.
        - {{ pin_subpackage("libarrow", exact=True) }}
        # compute is necessary even for a basic `import pyarrow`
        - {{ pin_subpackage("libarrow-compute", exact=True) }}
        - python
        # this is redundant with libarrow, but we want smithy to pick up that
        # cuda_compiler_version_min is present, to populate the CI configs
        - __cuda >={{ cuda_compiler_version_min }}  # [cuda_compiler_version != "None"]
      run_constrained:
        - apache-arrow-proc * {{ build_ext }}
        # keep lower pin aligned with run_exports from numpy
        # https://github.com/conda-forge/numpy-feedstock/blob/main/recipe/meta.yaml
        - numpy >=1.21,<3

    test:
      imports:
        - pyarrow
        # Compute can be imported but the underlying libarrow_acero is not present.
        - pyarrow.compute
        - pyarrow.orc
        - pyarrow.fs
        - pyarrow._s3fs
        - pyarrow._hdfs
        # We can only test importing cuda package but cannot run when a
        # CUDA device is not available, for instance, when building from CI.
        # On Windows, we cannot even do that due to `nvcuda.dll` not being found, see
        # https://conda-forge.org/docs/maintainer/knowledge_base.html#nvcuda-dll-cannot-be-found-on-windows
        # However, we check below for (at least) the presence of a correctly-compiled module
        - pyarrow.cuda     # [cuda_compiler_version != "None" and not win]
      commands:
        # libraries that depend on python (and hence aren't in libarrow itself)
        - test -f ${SP_DIR}/pyarrow/libarrow_python.so                              # [linux]
        - test -f ${SP_DIR}/pyarrow/libarrow_python_flight.so                       # [linux]
        - test -f ${SP_DIR}/pyarrow/libarrow_python_parquet_encryption.so           # [linux]
        - test -f ${SP_DIR}/pyarrow/libarrow_python.dylib                           # [osx]
        - test -f ${SP_DIR}/pyarrow/libarrow_python_flight.dylib                    # [osx]
        - test -f ${SP_DIR}/pyarrow/libarrow_python_parquet_encryption.dylib        # [osx]
        - if not exist %SP_DIR%\pyarrow\arrow_python.dll exit 1                     # [win]
        - if not exist %SP_DIR%\pyarrow\arrow_python_flight.dll exit 1              # [win]
        - if not exist %SP_DIR%\pyarrow\arrow_python_parquet_encryption.dll exit 1  # [win]

        - test -f ${SP_DIR}/pyarrow/include/arrow/python/pyarrow.h                  # [unix]
        - if not exist %SP_DIR%\pyarrow\include\arrow\python\pyarrow.h exit 1       # [win]

        - test ! -f ${SP_DIR}/pyarrow/tests/test_array.py                           # [unix]
        - if exist %SP_DIR%/pyarrow/tests/test_array.py exit 1                      # [win]
        # Need to remove dot from PY_VER; %MYVAR:x=y% replaces "x" in %MYVAR% with "y"
        - if not exist %SP_DIR%/pyarrow/_cuda.cp%PY_VER:.=%-win_amd64.pyd exit 1  # [win and cuda_compiler_version != "None"]

        # Expected not included libraries
        - test ! -f $PREFIX/lib/libarrow_acero${SHLIB_EXT}      # [unix]
        - test ! -f $PREFIX/lib/libarrow_dataset${SHLIB_EXT}    # [unix]
        - test ! -f $PREFIX/lib/libarrow_flight${SHLIB_EXT}     # [unix]
        - test ! -f $PREFIX/lib/libgandiva${SHLIB_EXT}          # [unix]
        - test ! -f $PREFIX/lib/libparquet${SHLIB_EXT}          # [unix]

    about:
      home: http://github.com/apache/arrow
      license: Apache-2.0
      license_file:
        - LICENSE.txt
      summary: Python libraries for Apache Arrow Core

  - name: pyarrow
    version: {{ version }}
    requirements:
      host:
        # only necessary for run-exports
        - python
      run:
        # Default doesn't contain flight, flight-sql and gandiva
        - {{ pin_subpackage("libarrow-acero", exact=True) }}
        - {{ pin_subpackage("libarrow-dataset", exact=True) }}
        - {{ pin_subpackage("libarrow-substrait", exact=True) }}
        - {{ pin_subpackage("libparquet", exact=True) }}
        # do not use pin_compatible because pyarrow-core has CUDA/non-CUDA variants
        - pyarrow-core {{ version }} *_{{ PKG_BUILDNUM }}_*
        - python

    test:
      files:
        - test_read_parquet.py
      imports:
        # default pyarrow contains parquet
        - pyarrow.dataset
        - pyarrow.parquet
      commands:
        # Expected not included libraries
        - test ! -f $PREFIX/lib/libarrow_flight${SHLIB_EXT}                        # [unix]
        - test ! -f $PREFIX/lib/libgandiva${SHLIB_EXT}                             # [unix]

        - python test_read_parquet.py

    about:
      home: http://github.com/apache/arrow
      license: Apache-2.0
      license_file:
        - LICENSE.txt
      summary: Python libraries for Apache Arrow with default capabilities

  - name: pyarrow-all
    version: {{ version }}
    requirements:
      host:
        # only necessary for run-exports
        - python
      run:
        - {{ pin_subpackage("libarrow-flight", exact=True) }}
        - {{ pin_subpackage("libarrow-flight-sql", exact=True) }}
        - {{ pin_subpackage("libarrow-gandiva", exact=True) }}
        - pyarrow {{ version }} *_{{ PKG_BUILDNUM }}
        - python

    test:
      imports:
        - pyarrow.flight
        - pyarrow.gandiva
    about:
      home: http://github.com/apache/arrow
      license: Apache-2.0
      license_file:
        - LICENSE.txt
      summary: Python libraries for Apache Arrow with all capabilities

  - name: pyarrow-tests
    script: build-pyarrow.sh   # [unix]
    script: build-pyarrow.bat  # [win]
    version: {{ version }}
    build:
      skip: true               # [cuda_compiler_version != "None"]
    requirements:
      build:
        - {{ compiler("c") }}
        - {{ stdlib("c") }}
        - {{ compiler("cxx") }}
        - python                                 # [build_platform != target_platform]
        - cross-python_{{ target_platform }}     # [build_platform != target_platform]
        - cython                                 # [build_platform != target_platform]
        - numpy                                  # [build_platform != target_platform]
        - cmake
        - ninja
      host:
        - {{ pin_subpackage("libarrow-all", exact=True) }}
        - pyarrow-all {{ version }} *_{{ PKG_BUILDNUM }}
        - clangdev {{ llvm_version }}
        - llvmdev {{ llvm_version }}
        - zlib
        - cython
        - numpy
        - python
        - setuptools
        - setuptools-scm
      run:
        - pyarrow-all {{ version }} *_{{ PKG_BUILDNUM }}
        - python

    {% if not (aarch64 or ppc64le) or py == 311 %}
    test:
      requires:
        # test_cpp_extension_in_python requires a compiler
        - {{ compiler("cxx") }}  # [linux]
        - pytest
        - boto3
        - cffi
        - cloudpickle
        - cython
        - fastparquet
        - fsspec
        - hypothesis
        - minio-server
        - pandas
        - s3fs >=2023
        - scipy
        - sparse        # [py<314]
        # these are generally (far) behind on migrating abseil/grpc/protobuf,
        # and using them as test dependencies blocks the migrator unnecessarily
        # - pytorch
        # - tensorflow
        # we're not building java bindings
        # - jpype1
        # doesn't get picked up correctly
        # - libhdfs3
      source_files:
        - cpp/submodules/parquet-testing/data
        - testing/data
      commands:
        - cd ${SP_DIR}                                      # [unix]
        - cd %SP_DIR%                                       # [win]
        - export ARROW_TEST_DATA="${SRC_DIR}/testing/data"  # [unix]
        - set "ARROW_TEST_DATA=%SRC_DIR%\testing\data"      # [win]
        - export PARQUET_TEST_DATA="${SRC_DIR}/cpp/submodules/parquet-testing/data"  # [unix]
        - set "PARQUET_TEST_DATA=%SRC_DIR%\cpp\submodules\parquet-testing\data"      # [win]

        {% set tests_to_skip = "_not_a_real_test" %}
        # we do not have GPUs in CI --> cannot test cuda
        {% set tests_to_skip = tests_to_skip + " or test_cuda" + " or test_dlpack_cuda_not_supported"%}
        # skip tests that raise SIGINT and crash the test suite
        {% set tests_to_skip = tests_to_skip + " or (test_csv and test_cancellation)" %}  # [linux]
        {% set tests_to_skip = tests_to_skip + " or (test_flight and test_interrupt)" %}  # [linux]
        # skip tests that make invalid(-for-conda) assumptions about the compilers setup
        {% set tests_to_skip = tests_to_skip + " or test_cython_api" %}                   # [unix]
        {% set tests_to_skip = tests_to_skip + " or test_visit_strings" %}                # [unix]
        # skip tests that cannot succeed in emulation
        {% set tests_to_skip = tests_to_skip + " or test_debug_memory_pool_disabled" %}   # [aarch64 or ppc64le]
        {% set tests_to_skip = tests_to_skip + " or test_env_var_io_thread_count" %}      # [aarch64 or ppc64le]
        # vvvvvvv TESTS THAT SHOULDN'T HAVE TO BE SKIPPED vvvvvvv
        # flaky test based on s3 connection
        {% set tests_to_skip = tests_to_skip + " or test_s3_real_aws_region_selection" %}
        # https://github.com/apache/arrow/issues/45229
        {% set tests_to_skip = tests_to_skip + " or test_sparse_coo_tensor_scipy_roundtrip" %}
        # this test is trying to simulate a failure mode using /usr/share/zoneinfo,
        # but newer orc will ignore that if it finds a tzinfo in a conda environment
        {% set tests_to_skip = tests_to_skip + " or test_timezone_absent" %}
        # https://github.com/apache/arrow/issues/43800
        {% set tests_to_skip = tests_to_skip + " or test_cpp_extension_in_python" %}                # [osx]
        # https://github.com/apache/arrow/issues/43356
        {% set tests_to_skip = tests_to_skip + " or (test_compute and test_assume_timezone)" %}     # [aarch64 or ppc64le]
        {% set tests_to_skip = tests_to_skip + " or (test_compute and test_strftime)" %}            # [aarch64 or ppc64le]
        {% set tests_to_skip = tests_to_skip + " or (test_compute and test_round_temporal)" %}      # [aarch64 or ppc64le]
        {% set tests_to_skip = tests_to_skip + " or test_extract_datetime_components " %}           # [aarch64 or ppc64le]
        # flaky test that fails regularly on aarch
        {% set tests_to_skip = tests_to_skip + " or test_feather_format[serial]" %}                 # [aarch64 or ppc64le]
        # gandiva tests are segfaulting on ppc
        {% set tests_to_skip = tests_to_skip + " or test_gandiva" %}                                # [ppc64le]
        # ^^^^^^^ TESTS THAT SHOULDN'T HAVE TO BE SKIPPED ^^^^^^^
        - pytest pyarrow/ -rfEs -k "not ({{ tests_to_skip }})"
    {% endif %}

    about:
      home: http://github.com/apache/arrow
      license: Apache-2.0
      license_file:
        - LICENSE.txt
      summary: Python test files for Apache Arrow

about:
  home: http://github.com/apache/arrow
  license: Apache-2.0
  license_file:
    - LICENSE.txt
  summary: C++ libraries for Apache Arrow

extra:
  recipe-maintainers:
    - wesm
    - xhochy
    - leifwalsh
    - jreback
    - cpcloud
    - pcmoritz
    - robertnishihara
    - siddharthteotia
    - kou
    - kszucs
    - pitrou
    - pearu
    - nealrichardson
    - jakirkham
    - h-vetinari
    - raulcd
  feedstock-name: arrow-cpp
