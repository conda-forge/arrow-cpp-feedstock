{% set version = "8.0.1" %}
{% set cuda_enabled = cuda_compiler_version != "None" %}
{% set build_ext_version = "3.0.0" %}
{% set build_ext = "cuda" if cuda_enabled else "cpu" %}
{% set proc_build_number = "0" %}
{% set llvm_version = "14" %}

package:
  name: arrow-cpp-ext
  version: {{ version }}

source:
  url: https://dist.apache.org/repos/dist/release/arrow/arrow-{{ version }}/apache-arrow-{{ version }}.tar.gz
  sha256: 82d46929f7574715551da21700f100b39f99c3c4d6790f26cac86d869d64e94e
  patches:
    # minimal backport of the following commit for compatibility with VS2019
    # https://github.com/apache/arrow/commit/897c186f475f3dd82c1ab47e5cfb87cb0fed8440
    - patches/0001-ARROW-17433-CI-C-Use-Visual-Studio-2019-on-AppVeyor-.patch
    # jemalloc version bump to be able to cross-compile on osx-arm
    - patches/0002-ARROW-16730-C-Bump-vendored-jemalloc-version-13294.patch

# ensure cuda_compiler_version_min gets picked up by conda-smithy
# [cuda_compiler_version_min == "something"]

build:
  number: 20
  # for cuda support, building with one version is enough to be compatible with
  # all later versions, since arrow is only using libcuda, and not libcudart.
  skip: true  # [cuda_compiler_version not in ("None", cuda_compiler_version_min)]
  # CUDA builds on ppc64le currently run out of time on Travis CI.
  # It may be possible to move these to cross-compilation, but this will take additional work.
  # Hence this is skipped for now until this can be addressed.
  skip: true  # [linux and ppc64le and cuda_compiler_version != "None"]
  run_exports:
    - {{ pin_subpackage("arrow-cpp", max_pin="x.x.x") }}

outputs:
  - name: arrow-cpp-proc
    version: {{ build_ext_version }}
    build:
      number: {{ proc_build_number }}
      string: {{ build_ext }}
    test:
      commands:
        - exit 0
    about:
      home: http://github.com/apache/arrow
      license: Apache-2.0
      license_file:
        - LICENSE.txt
      summary: A meta-package to select Arrow build variant

  - name: arrow-cpp
    script: build-arrow.sh  # [not win]
    script: bld-arrow.bat   # [win]
    version: {{ version }}
    build:
      string: py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}_{{ build_ext }}
      run_exports:
        - {{ pin_subpackage("arrow-cpp", max_pin="x.x.x") }}
      ignore_run_exports:
        - cudatoolkit
      track_features: {{ "[arrow-cuda]" if cuda_enabled else "" }}
      missing_dso_whitelist:
        - "*/libcuda.so.*"    # [linux]
        - "*/nvcuda.dll"      # [win]
    requirements:
      build:
        - python                                 # [build_platform != target_platform]
        - cross-python_{{ target_platform }}     # [build_platform != target_platform]
        - cython                                 # [build_platform != target_platform]
        - numpy                                  # [build_platform != target_platform]
        - clangdev {{ llvm_version }}            # [osx and arm64]
        - llvmdev {{ llvm_version }}             # [osx and arm64]
        - gnuconfig                              # [osx and arm64]
        - libgrpc
        - libprotobuf
        - cmake
        - autoconf  # [unix]
        - ninja
        - make  # [unix]
        - {{ compiler('c') }}
        - {{ compiler('cxx') }}
        - {{ compiler("cuda") }}  # [cuda_compiler_version != "None"]
      host:
        - aws-crt-cpp  # [unix]
        - aws-sdk-cpp
        # abseil is only here to help conda pick the right constraints for pyarrow, see
        # https://github.com/conda-forge/arrow-cpp-feedstock/pull/815#issuecomment-1216713245
        - libabseil
        - boost-cpp >=1.70
        - brotli
        - bzip2
        - c-ares
        - gflags
        - glog
        - google-cloud-cpp
        # since libgoogle-cloud is static on windows, see
        # https://github.com/conda-forge/google-cloud-cpp-feedstock/pull/108,
        # its dependencies leak into the build here
        - libcrc32c  # [win]
        - libcurl    # [win]
        - libgrpc
        - libprotobuf
        - clangdev {{ llvm_version }}
        - llvmdev {{ llvm_version }}
        - libutf8proc
        - lz4-c
        - numpy
        # gandiva depends on openssl
        - openssl
        - orc          # [unix]
        - python
        - rapidjson
        - re2
        - snappy
        - thrift-cpp
        # 8.0.1 pins xsimd to a specific commit; use version required by 9.0.0, see
        # https://github.com/apache/arrow/blob/apache-arrow-9.0.0/cpp/cmake_modules/ThirdpartyToolchain.cmake#L2245
        - xsimd 8.1.0
        - zlib
        - zstd
      run:
        - {{ pin_compatible('numpy', lower_bound='1.16') }}
        - python
      run_constrained:
        - arrow-cpp-proc * {{ build_ext }}
        - cudatoolkit >=9.2  # [cuda_compiler_version != "None"]

    about:
      home: http://github.com/apache/arrow
      license: Apache-2.0
      license_file:
        - LICENSE.txt
      summary: C++ libraries for Apache Arrow

    test:
      commands:
        {% set headers = [
            "arrow/api.h", "arrow/flight/types.h", "gandiva/engine.h", "parquet/api/reader.h"
        ] %}
        {% set headers = headers + ["arrow/flight/sql/api.h", "plasma/client.h"] %}  # [unix]
        {% for each_header in headers %}
        # headers
        - test -f $PREFIX/include/{{ each_header }} || (echo "{{ each_header }} not found" && exit 1)  # [unix]
        - if not exist %LIBRARY_INC%\{{ "\\".join(each_header.split("/")) }} exit 1                    # [win]
        {% endfor %}

        {% set libs = (cuda_compiler_version != "None") * ["arrow_cuda"] + [
            "arrow", "arrow_dataset", "arrow_flight", "arrow_python",
            "arrow_substrait", "gandiva", "parquet"
        ] %}
        {% set libs = libs + ["arrow_flight_sql", "plasma"] %}     # [unix]
        {% for each_lib in libs %}
        # shared
        - test -f $PREFIX/lib/lib{{ each_lib }}.so                 # [linux]
        - test -f $PREFIX/lib/lib{{ each_lib }}.dylib              # [osx]
        - if not exist %LIBRARY_BIN%\{{ each_lib }}.dll exit 1     # [win]
        - if not exist %LIBRARY_LIB%\{{ each_lib }}.lib exit 1     # [win]

        # absence of static libraries
        - test ! -f $PREFIX/lib/lib{{ each_lib }}.a                # [unix]
        - if exist %LIBRARY_LIB%\{{ each_lib }}_static.lib exit 1  # [win]
        {% endfor %}

        # absence of arrow_cuda for CPU builds
        - test ! -f $PREFIX/lib/libarrow_cuda.so                   # [(cuda_compiler_version == "None") and linux]
        - test ! -f $PREFIX/lib/libarrow_cuda.a                    # [(cuda_compiler_version == "None") and linux]
        - if exist %LIBRARY_BIN%\arrow_cuda.dll exit 1             # [(cuda_compiler_version == "None") and win]
        - if exist %LIBRARY_LIB%\arrow_cuda.lib exit 1             # [(cuda_compiler_version == "None") and win]
        - if exist %LIBRARY_LIB%\arrow_cuda_static.lib exit 1      # [(cuda_compiler_version == "None") and win]

  - name: pyarrow
    script: build-pyarrow.sh  # [not win]
    script: bld-pyarrow.bat   # [win]
    version: {{ version }}
    build:
      string: py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}_{{ build_ext }}
      ignore_run_exports:
        - cudatoolkit
      track_features: {{ "[arrow-cuda]" if cuda_enabled else "" }}
    requirements:
      build:
        - python                                 # [build_platform != target_platform]
        - cross-python_{{ target_platform }}     # [build_platform != target_platform]
        - cython                                 # [build_platform != target_platform]
        - numpy                                  # [build_platform != target_platform]
        - cmake
        - ninja
        - make  # [unix]
        - {{ compiler('c') }}
        - {{ compiler('cxx') }}
        # pyarrow does not require nvcc but it needs to link against libraries in arrow-cpp=*=*cuda
        - {{ compiler("cuda") }}  # [cuda_compiler_version != "None"]
      host:
        - {{ pin_subpackage('arrow-cpp', exact=True) }}
        - cython
        - gflags  # [unix]
        - numpy
        - python
        - setuptools
        - setuptools_scm
      run:
        - {{ pin_subpackage('arrow-cpp', exact=True) }}
        - {{ pin_compatible('numpy', lower_bound='1.16') }}
        # empty parquet-cpp metapackage, force old versions to be uninstalled
        - parquet-cpp 1.5.1.*
        - python
      run_constrained:
        - arrow-cpp-proc * {{ build_ext }}
        - cudatoolkit >=9.2  # [cuda_compiler_version != "None"]

    about:
      home: http://github.com/apache/arrow
      license: Apache-2.0
      license_file:
        - LICENSE.txt
      summary: Python libraries for Apache Arrow

    test:
      files:
        - test_read_parquet.py
      imports:
        - pyarrow
        - pyarrow.dataset
        - pyarrow.flight
        - pyarrow.gandiva
        - pyarrow.orc      # [unix]
        - pyarrow.parquet
        - pyarrow.plasma   # [unix]
        - pyarrow.fs
        - pyarrow._s3fs
        - pyarrow._hdfs
        # We can only test importing cuda package but cannot run when a
        # CUDA device is not available, for instance, when building from CI.
        # On Windows, we cannot even do that due to `nvcuda.dll` not being found, see
        # https://conda-forge.org/docs/maintainer/knowledge_base.html#nvcuda-dll-cannot-be-found-on-windows
        # However, we check below for (at least) the presence of a correctly-compiled module
        - pyarrow.cuda     # [cuda_compiler_version != "None" and not win]
      commands:
        - test ! -f ${SP_DIR}/pyarrow/tests/test_array.py                         # [unix]
        - if exist %SP_DIR%/pyarrow/tests/test_array.py exit 1                    # [win]
        # Need to remove dot from PY_VER; %MYVAR:x=y% replaces "x" in %MYVAR% with "y"
        - if not exist %SP_DIR%/pyarrow/_cuda.cp%PY_VER:.=%-win_amd64.pyd exit 1  # [win and cuda_compiler_version != "None"]
        - python test_read_parquet.py

  - name: pyarrow-tests
    script: build-pyarrow.sh  # [not win]
    script: bld-pyarrow.bat   # [win]
    version: {{ version }}
    build:
      string: py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}_{{ build_ext }}
      ignore_run_exports:
        - cudatoolkit
      track_features: {{ "[arrow-cuda]" if cuda_enabled else "" }}
    requirements:
      build:
        - python                                 # [build_platform != target_platform]
        - cross-python_{{ target_platform }}     # [build_platform != target_platform]
        - cython                                 # [build_platform != target_platform]
        - numpy                                  # [build_platform != target_platform]
        - cmake
        - ninja
        - make  # [unix]
        - {{ compiler('c') }}
        - {{ compiler('cxx') }}
        # pyarrow does not require nvcc but it needs to link against libraries in arrow-cpp=*=*cuda
        - {{ compiler("cuda") }}  # [cuda_compiler_version != "None"]
      host:
        - {{ pin_subpackage('arrow-cpp', exact=True) }}
        - {{ pin_subpackage('pyarrow', exact=True) }}
        - cython
        - numpy
        - python
        - setuptools
        - setuptools_scm
      run:
        - {{ pin_subpackage('pyarrow', exact=True) }}
        - python
      run_constrained:
        - arrow-cpp-proc * {{ build_ext }}
        - cudatoolkit >=9.2  # [cuda_compiler_version != "None"]

    about:
      home: http://github.com/apache/arrow
      license: Apache-2.0
      license_file:
        - LICENSE.txt
      summary: Python test files for Apache Arrow

    test:
      commands:
        - test -f ${SP_DIR}/pyarrow/tests/test_array.py             # [unix]
        - if not exist %SP_DIR%/pyarrow/tests/test_array.py exit 1  # [win]

about:
  home: http://github.com/apache/arrow
  license: Apache-2.0
  license_file:
    - LICENSE.txt
  summary: C++ and Python libraries for Apache Arrow

extra:
  recipe-maintainers:
    - wesm
    - xhochy
    - leifwalsh
    - jreback
    - cpcloud
    - pcmoritz
    - robertnishihara
    - siddharthteotia
    - kou
    - kszucs
    - pitrou
    - pearu
    - nealrichardson
    - jakirkham
